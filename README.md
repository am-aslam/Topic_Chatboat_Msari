# üß† Offline Topic ChatBot (FastAPI + Llama.cpp)

An offline, privacy-focused **AI Topic Chatbot** built using **FastAPI** and **Llama.cpp**.  
This chatbot runs fully offline, detects language automatically, supports topic-based conversations, and assigns unique session IDs to maintain context.

---

## üöÄ Features

- ‚úÖ **Works Completely Offline** ‚Äì No internet required
- üß† **Llama.cpp GGUF model** for fast inference
- üåç **Automatic Language Detection** (Multi-language support)
- üßµ **Session-based conversations** by topic
- ‚ö° Lightweight ‚Äî Works on CPU
- üîå Can be integrated with Web UI, Desktop UI, or Mobile
- üõ°Ô∏è **Fully Private** ‚Äì Your data stays on your system

---

## üìÇ Project Structure

ChatBoat/
‚îÇ‚îÄ‚îÄ index.html # Frontend UI
‚îÇ‚îÄ‚îÄ main.py # FastAPI Backend
‚îÇ‚îÄ‚îÄ requirements.txt # Python Dependencies
‚îÇ‚îÄ‚îÄ models/ # Place your GGUF Model here
‚îî‚îÄ‚îÄ venv/ # (Optional) Virtual Environment


---

## üì• Download AI Model (Required)

Download the GGUF model and place it inside the `models` folder.

üîó **Model Download Link:**  
https://huggingface.co/am-as1am/Llama-3.2-3B-Instruct-Q4_0/blob/main/mistral-7b-openorca.gguf2.Q4_0.gguf

> After downloading, move the model into the `models` directory and make sure the filename matches the path used inside `main.py`.

---

## ‚öôÔ∏è Installation & Setup

### 1Ô∏è‚É£ Clone the Repository

```bash
git clone https://github.com/<your-username>/<your-repo-name>.git
cd ChatBoat

2Ô∏è‚É£ Create & Activate Virtual Environment (Recommended)
python -m venv venv


Activate it:

OS	Command
Windows	venv\Scripts\activate
Mac/Linux	source venv/bin/activate

3Ô∏è‚É£ Install Dependencies
pip install -r requirements.txt

‚ñ∂Ô∏è Run the Backend Server
python main.py
